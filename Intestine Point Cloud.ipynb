{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AIM: Create a 3d model of the worm c.elegans from planar images of it\n",
    "  * Create an accurate point cloud of the intestine and worm body\n",
    "    * 3d CLAHE applied to image stack\n",
    "    * 3d median filter\n",
    "    * binarise images\n",
    "    * morphological transformations (erosion to remove noise)\n",
    "    * Converted into a point cloud \n",
    "    * Took slices of the point cloud from the z axis\n",
    "      * Ran the convex hull algorithm on each slice\n",
    "      * Drew convex hull on each slice\n",
    "      * Working on converting these into a point cloud\n",
    "    - I have been able to clear most of the noise in the images\n",
    "    - Still need to be able to reliably distinguish the intestine and worm body\n",
    "  * Create a 3d mesh of the intestine and worm body\n",
    "  * Convert the mesh into an estimate of the worm body identifying:\n",
    "    * twist of intestine (without twist of worm body)\n",
    "    * twist of intestine and worm body\n",
    "  * Further considerations:\n",
    "    * Ignoring parts of certain images where they are blurry when generating pioint cloud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But overall, my thoughts are as follows:\n",
    "*The general metric of Ricci Curvature is best suited to measuring Reimannian curvature in higher dimensions as I require for this problem.\n",
    "* However, this relies on having a graph structure to run. Note this is not just a mesh of the outline of the shape, but a tesnor that is represents the entire shape\n",
    "* The paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import skimage.io\n",
    "from scipy.ndimage import median_filter\n",
    "from scipy import signal\n",
    "from skimage import exposure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cloudconvert.com/tif-to-jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "subfolder = 'testimages/2022.12.21_APS018_Infection_PA14-GacA_40X_40 _EM-4_D2_3_7047-1,2022.12.21_APS018_Infection_PA14[...]'\n",
    "# sub = '2022.12.21_APS018_Infection_PA14-GacA_40X_40 _EM-4_D2_3_7047-'\n",
    "for i in range(14): # number of tif layers\n",
    "    address = subfolder + '/' + str(i+1) + '.jpg'\n",
    "    img = skimage.io.imread(address)\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in images:\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skimage.io.imsave('base_image.jpg', images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equalised_images = []\n",
    "# clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(10,10))\n",
    "\n",
    "# for i in range(len(images)):\n",
    "#     img = clahe.apply(images[i])\n",
    "#     equalised_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equalised_images = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_images = np.stack(images, axis=2)\n",
    "np_equalised_images = exposure.equalize_adapthist(np_images, clip_limit=0.03)\n",
    "equalised_images = np.split(np_equalised_images, np_equalised_images.shape[2], axis=2)\n",
    "equalised_images = [np.squeeze(img) for img in equalised_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eqimg in equalised_images:\n",
    "    cv2.imshow('image', eqimg)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# med_blur_images = []\n",
    "# for i in range(len(equalised_images)):\n",
    "#     scaled_image = cv2.normalize(equalised_images[i], None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "#     medimg = cv2.medianBlur(scaled_image, 3) # 21\n",
    "#     med_blur_images.append(medimg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_images = np.stack(equalised_images, axis=2)\n",
    "med_blur_images_numpyarray = signal.medfilt(eq_images, kernel_size=(3,3,3))\n",
    "med_blur_images = np.split(med_blur_images_numpyarray, med_blur_images_numpyarray.shape[2], axis=2)\n",
    "med_blur_images = [np.squeeze(img) for img in med_blur_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for med_img in med_blur_images:\n",
    "    cv2.imshow('image', med_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_float64_to_uint8(float64_images):\n",
    "#     uint8_images = []\n",
    "#     for float64_image in float64_images:\n",
    "#         # Normalize pixel values to the range [0, 255]\n",
    "#         norm_image = cv2.normalize(float64_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "#         # Convert data type to uint8\n",
    "#         uint8_image = norm_image.astype(np.uint8)\n",
    "#         uint8_images.append(uint8_image)\n",
    "#     return uint8_images\n",
    "\n",
    "# uint8_med_blur = convert_float64_to_uint8(med_blur_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_float64_to_uint8(float64_images):\n",
    "    uint8_images = []\n",
    "    for float64_image in float64_images:\n",
    "        # Normalize pixel values to the range [0, 255]\n",
    "        # norm_image = cv2.normalize(float64_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        # Convert data type to uint8\n",
    "        uint8_image = float64_image.astype(np.uint8)\n",
    "        uint8_images.append(uint8_image)\n",
    "    return uint8_images\n",
    "\n",
    "uint8_med_blur = convert_float64_to_uint8(med_blur_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for med_img in uint8_med_blur:\n",
    "    cv2.imshow('image', med_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_images = []\n",
    "for med_img in uint8_med_blur:\n",
    "    _, binary_image = cv2.threshold(med_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    # binary_image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # _, binary_image = cv2.threshold(eqimg, 0, 255, cv2.THRESH_BINARY)\n",
    "    binary_images.append(binary_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bin_img in binary_images:\n",
    "    # plt.imshow(bin_img, cmap='gray')\n",
    "    # plt.show()\n",
    "    cv2.imshow('binary image', bin_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 5\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_OPEN, (kernel_size, kernel_size))\n",
    "\n",
    "# Apply morphological closing operation to each binary image\n",
    "closed_images = []\n",
    "for binary_image in binary_images:\n",
    "    closed_img = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel, iterations=5)\n",
    "    closed_images.append(closed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls_img in closed_images:\n",
    "    # plt.imshow(bin_img, cmap='gray')\n",
    "    # plt.show()\n",
    "    cv2.imshow('binary image', cls_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pixel coordinates and map them to 3D space\n",
    "coords = []\n",
    "for i, image in enumerate(closed_images):\n",
    "    coords_i = np.column_stack(np.where(image > 0))\n",
    "    coords_i = np.hstack((coords_i, np.full((coords_i.shape[0], 1), -i)))  # Mapping to Z-coordinate\n",
    "    coords.append(coords_i)\n",
    "\n",
    "# Combine the pixel coordinates from all images\n",
    "all_coords = np.concatenate(coords)\n",
    "\n",
    "# Scale and normalize the coordinates\n",
    "scale_factor_z = 3  # Adjust the scale factor for the z-axis as needed\n",
    "all_coords[:, 2] = all_coords[:, 2] * scale_factor_z\n",
    "\n",
    "# Calculate the center of the point cloud\n",
    "center = np.mean(all_coords, axis=0)\n",
    "\n",
    "# Translate the coordinates to center the point cloud\n",
    "all_coords[:, 0] = all_coords[:, 0] - center[0]\n",
    "all_coords[:, 1] = all_coords[:, 1] - center[1]\n",
    "all_coords[:, 2] = all_coords[:, 2] - center[2]\n",
    "\n",
    "# Create a point cloud\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "point_cloud.points = o3d.utility.Vector3dVector(all_coords[:, [1, 0, 2]])  # Swap X and Y axes for Open3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the point cloud\n",
    "downpcd = point_cloud.voxel_down_sample(voxel_size=0.0001)\n",
    "\n",
    "o3d.visualization.draw_geometries([point_cloud],\n",
    "                                  zoom=1,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[0, 0, 0],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024],\n",
    "                                  point_show_normal=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the normals of the point cloud\n",
    "point_cloud.estimate_normals()\n",
    "\n",
    "# Estimate the radius for the rolling ball\n",
    "distances = point_cloud.compute_nearest_neighbor_distance()\n",
    "avg_dist = np.mean(distances)\n",
    "radius = 1.5 * avg_dist\n",
    "\n",
    "# Create the mesh using the Ball Pivoting Algorithm\n",
    "mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(\n",
    "    point_cloud, o3d.utility.DoubleVector([radius, radius * 2])\n",
    ")\n",
    "\n",
    "# Visualize the mesh\n",
    "o3d.visualization.draw_geometries([mesh])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_coords[:, [2, 1, 0]] = all_coords[:, [1, 0, 2]]  # Swap back X and Y axes\n",
    "all_coords[:, 0] = all_coords[:, 0] + center[0]\n",
    "all_coords[:, 1] = all_coords[:, 1] + center[1]\n",
    "all_coords[:, 2] = all_coords[:, 2] + center[2]\n",
    "\n",
    "inverse_scale_factor_z = 1 / scale_factor_z\n",
    "all_coords[:, 2] = all_coords[:, 2] * inverse_scale_factor_z\n",
    "\n",
    "layer_coords = {}\n",
    "for coord in all_coords:\n",
    "    z = coord[2]\n",
    "    if z not in layer_coords:\n",
    "        layer_coords[z] = []\n",
    "    layer_coords[z].append(coord)\n",
    "\n",
    "reconstructed_images = []\n",
    "for z, layer in layer_coords.items():\n",
    "    layer_coords_np = np.array(layer)\n",
    "    layer_coords_np[:, [0, 1]] = layer_coords_np[:, [1, 0]]  # Swap X and Y axes\n",
    "    layer_coords_np[:, 0] = layer_coords_np[:, 0] - np.min(layer_coords_np[:, 0])\n",
    "    layer_coords_np[:, 1] = layer_coords_np[:, 1] - np.min(layer_coords_np[:, 1])\n",
    "    image_shape = (np.max(layer_coords_np[:, 0]) + 1, np.max(layer_coords_np[:, 1]) + 1)\n",
    "    binary_image = np.zeros(image_shape, dtype=np.uint8)\n",
    "    binary_image[layer_coords_np[:, 0], layer_coords_np[:, 1]] = 255\n",
    "    reconstructed_images.append(binary_image)\n",
    "\n",
    "# Display the reconstructed images separately\n",
    "# for i, image in enumerate(reconstructed_images):\n",
    "#     plt.figure()\n",
    "#     plt.imshow(image, cmap='gray')\n",
    "#     plt.axis('off')\n",
    "#     plt.title(f\"Reconstructed Image {i+1}\")\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assume the code to reconstruct the point cloud and generate 'reconstructed_images' is present\n",
    "\n",
    "# # Apply Convex Hull and display the results on separate images\n",
    "# for i, image in enumerate(reconstructed_images):\n",
    "#     # Find contours in the image\n",
    "#     contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#     # Create a blank image for displaying the convex hulls\n",
    "#     convex_hull_image = np.zeros_like(image)\n",
    "\n",
    "#     # Draw convex hulls on the image\n",
    "#     for contour in contours:\n",
    "#         hull = cv2.convexHull(contour)\n",
    "#         cv2.drawContours(convex_hull_image, [hull], 0, 255, 2)\n",
    "\n",
    "#     # # Display the original reconstructed image and the image with convex hulls side by side\n",
    "#     # fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "#     # axes[0].imshow(image, cmap='gray')\n",
    "#     # axes[0].axis('off')\n",
    "#     # axes[0].set_title(f\"Reconstructed Image {i+1}\")\n",
    "#     # axes[1].imshow(convex_hull_image, cmap='gray')\n",
    "#     # axes[1].axis('off')\n",
    "#     # axes[1].set_title(f\"Convex Hulls on Image {i+1}\")\n",
    "\n",
    "#     # plt.tight_layout()\n",
    "#     # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the code to reconstruct the point cloud and generate 'reconstructed_images' is present\n",
    "\n",
    "# Convert images with convex hulls back into a point cloud\n",
    "coords = []\n",
    "for i, image in enumerate(reconstructed_images):\n",
    "    # Extract pixel coordinates\n",
    "    coords_i = np.column_stack(np.where(image > 0))\n",
    "    coords_i = np.hstack((coords_i, np.full((coords_i.shape[0], 1), -i)))  # Mapping to Z-coordinate\n",
    "    coords.append(coords_i)\n",
    "\n",
    "# Combine the pixel coordinates from all images\n",
    "all_coords = np.concatenate(coords)\n",
    "\n",
    "# Scale and normalize the coordinates\n",
    "scale_factor_z = 1  # Adjust the scale factor for the z-axis as needed\n",
    "all_coords[:, 2] = all_coords[:, 2] * scale_factor_z\n",
    "\n",
    "# Calculate the center of the point cloud\n",
    "center = np.mean(all_coords, axis=0)\n",
    "\n",
    "# Translate the coordinates to center the point cloud\n",
    "all_coords[:, 0] = all_coords[:, 0] - center[0]\n",
    "all_coords[:, 1] = all_coords[:, 1] - center[1]\n",
    "all_coords[:, 2] = all_coords[:, 2] - center[2]\n",
    "\n",
    "# Create a point cloud\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "point_cloud.points = o3d.utility.Vector3dVector(all_coords[:, [1, 0, 2]])  # Swap X and Y axes for Open3D\n",
    "\n",
    "# Visualize the point cloud\n",
    "downpcd = point_cloud.voxel_down_sample(voxel_size=0.01)\n",
    "\n",
    "o3d.visualization.draw_geometries([point_cloud],\n",
    "                                  zoom=1,\n",
    "                                  front=[0.4257, -0.2125, -0.8795],\n",
    "                                  lookat=[0, 0, 0],\n",
    "                                  up=[-0.0694, -0.9768, 0.2024],\n",
    "                                  point_show_normal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assume the code to reconstruct the point cloud and generate 'reconstructed_images' is present\n",
    "\n",
    "# # Detect circles using Hough Circle Transform and display them on separate images\n",
    "# for i, image in enumerate(reconstructed_images):\n",
    "#     # Apply Gaussian blur to reduce noise (adjust parameters as needed)\n",
    "#     blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "#     # Apply Hough Circle Transform (adjust parameters as needed)\n",
    "#     circles = cv2.HoughCircles(blurred_image, cv2.HOUGH_GRADIENT, dp=1, minDist=30,\n",
    "#                                param1=50, param2=30, minRadius=5, maxRadius=20)\n",
    "\n",
    "#     # Create a blank image for displaying the circles\n",
    "#     circle_image = np.zeros_like(image)\n",
    "\n",
    "#     # Draw detected circles on the circle image\n",
    "#     if circles is not None:\n",
    "#         circles = np.uint16(np.around(circles))\n",
    "#         for circle in circles[0, :]:\n",
    "#             center = (circle[0], circle[1])\n",
    "#             radius = circle[2]\n",
    "#             cv2.circle(circle_image, center, radius, 255, 2)\n",
    "\n",
    "#     # Display the original reconstructed image and the circle image side by side\n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "#     axes[0].imshow(image, cmap='gray')\n",
    "#     axes[0].axis('off')\n",
    "#     axes[0].set_title(f\"Reconstructed Image {i+1}\")\n",
    "#     axes[1].imshow(circle_image, cmap='gray')\n",
    "#     axes[1].axis('off')\n",
    "#     axes[1].set_title(f\"Hough Circles on Image {i+1}\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydiffmap import diffusion_map as dm\n",
    "# # from pydiffmap.kernel import VariableBandwidthKernel\n",
    "\n",
    "# data = np.asarray(point_cloud.points)\n",
    "\n",
    "# # Construct a Gaussian kernel object\n",
    "# kernel_object = dm.kernel.Kernel(kernel_type='gaussian', epsilon='bgh')\n",
    "\n",
    "# # Create an instance of the DiffusionMap class\n",
    "# dmap = dm.DiffusionMap(kernel_object=kernel_object, n_evecs=3)\n",
    "\n",
    "# # Compute the diffusion map\n",
    "# dmap_data = dmap.fit_transform(data)\n",
    "\n",
    "# from pydiffmap import visualization as vis\n",
    "\n",
    "# vis.data_plot(dmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
